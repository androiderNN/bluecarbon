{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "train = pd.read_csv('./raws/train_data.csv')\n",
    "test = pd.read_csv('./raws/test_data.csv')\n",
    "\n",
    "train = train.loc[:, 'lat':'MIN_WVP']\n",
    "test = test.loc[:, 'lat':'MIN_WVP']\n",
    "\n",
    "train = train.drop(columns=['Landsat_StartTime', 'PRODUCT_ID'])\n",
    "test = test.drop(columns=['Landsat_StartTime', 'PRODUCT_ID'])\n",
    "\n",
    "pickle.dump(train, open('./processed/shrinked_train.pkl', 'wb'))\n",
    "pickle.dump(test, open('./processed/shrinked_test.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurecreation(df, istrain):\n",
    "    # 切り出し\n",
    "    # df = df.loc[:, 'lat':'sst_diff']\n",
    "    df = df.loc[:, 'lat':'MIN_WVP']\n",
    "\n",
    "    # # 海岸の比率\n",
    "    df['beach_rate'] = df['beach_length'] / df['coast_length']\n",
    "    # df['aicial_rate'] = df['aicial_length'] / df['coast_length']\n",
    "\n",
    "    # 透明度推定\n",
    "    # df['SS_est'] = (df['Green']-df['SWIR2']) / (df['Red']-df['SWIR2'])\n",
    "    df['Chla_est'] = (df['Blue']-df['SWIR2']) / (df['Red']-df['SWIR2'])\n",
    "\n",
    "    # depthの処理\n",
    "    # df.loc[df['depth']==0, 'depth'] = np.nan\n",
    "    # df['dfdiff'] = df['depth_original'] - df['depth']\n",
    "    # df.loc[~(df['depth_original'].isna()), 'depth'] = np.nan\n",
    "\n",
    "    # depth_original推定\n",
    "    # if istrain == 1:\n",
    "    #     global domodel\n",
    "    #     domodel = depth_original_estimation(df)\n",
    "    # for i in range(4):\n",
    "    #     df['dopred'+str(i)] = domodel[i].predict(df, predict_disable_shape_check=True)\n",
    "    # df['depth_pred'] = df[['dopred'+str(i) for i in range(4)]].mean(axis=1)\n",
    "    # df = df.drop(columns=['dopred'+str(i) for i in range(4)])\n",
    "    \n",
    "    # 文献の分類\n",
    "    # df['YMDstyle'] = [str(str(i).count('-')) +'_'+ str(str(i).count('.')) for i in list(df['YMD'])]\n",
    "    # df['YMDstyle'].replace(['0_4', '1_2', '2_12', '0_2'], np.nan, inplace=True)\n",
    "    # df['YMDstyle'].replace(['0_0', '0_1', '0_2', '0_4', '1_2', '1_4', '2_12'], [2, 1, 3, np.nan, np.nan, 4, np.nan], inplace=True)\n",
    "\n",
    "    # 必要な列の抽出\n",
    "    col = ['Chla_est']\n",
    "    df = pd.concat([df.loc[:, 'lat':'sst_diff'], df.loc[:, col]], axis=1)\n",
    "    col = ['year', 'month', 'YMD', 'area', 'lon', 'lat', 'cliff_length', 'Salinity_annual', 'river_area', 'sst_diff']\n",
    "    df.drop(columns=col, inplace=True)\n",
    "    # df = df.loc[:, ['cover', 'depth_original','area','YMDstyle','warm_sst','fetch','depth','hist_warm_sst','coastal_dist','Salinity_annual','coast_length','aicial_length','sst_diff']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_original_estimation(df):\n",
    "    print('depth_original feature estimating...')\n",
    "    print('===========================================================\\n')\n",
    "\n",
    "    train_p = df.loc[~(df['depth_original'].isna()), :]\n",
    "\n",
    "    x = train_p.drop(columns=['cover', 'depth_original'], errors='ignore')\n",
    "    y = train_p['depth_original']\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=234)\n",
    "    c = 0\n",
    "    model = []\n",
    "    \n",
    "    for idx_tr, idx_va in kf.split(train_p):\n",
    "        tr_x, va_x = x.iloc[idx_tr], x.iloc[idx_va]\n",
    "        tr_y, va_y = y.iloc[idx_tr], y.iloc[idx_va]\n",
    "\n",
    "        lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "        lgb_val = lgb.Dataset(va_x, va_y)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'verbose': -1,\n",
    "            'random_state': 254,\n",
    "            # 'min_data_in_leaf': 200,\n",
    "            # 'bagging_fraction': 0.5,\n",
    "            # 'bagging_freq': 1,\n",
    "            'lambda_l1': 0.5,\n",
    "            'lambda_l2': 0.5,\n",
    "        }\n",
    "\n",
    "        model.append(lgb.train(\n",
    "            params,\n",
    "            lgb_train,\n",
    "            valid_sets=[lgb_train, lgb_val],\n",
    "            valid_names=['train', 'val'],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=3, verbose=True)]\n",
    "        ))\n",
    "\n",
    "    print('\\n===========================================================\\n')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nn_data(df, istrain):\n",
    "    # depth_original推定\n",
    "    if istrain == 1:\n",
    "        global domodel\n",
    "        domodel = depth_original_estimation(df)\n",
    "    for i in range(4):\n",
    "        df['dopred'+str(i)] = domodel[i].predict(df, predict_disable_shape_check=True)\n",
    "    df['depth_pred'] = df[['dopred'+str(i) for i in range(4)]].mean(axis=1)\n",
    "    df['depth_original'].fillna(df['depth_pred'], inplace=True)\n",
    "    df = df.drop(columns=['dopred'+str(i) for i in range(4)]+['depth_pred'])\n",
    "\n",
    "    # 穴埋め\n",
    "    for col in df.columns:\n",
    "        df[col].fillna(df[col].mean(numeric_only=True), inplace=True)\n",
    "    \n",
    "    #標準化\n",
    "    if istrain == 1:\n",
    "        global mea\n",
    "        global std\n",
    "        mea = df.drop(columns='cover').mean()\n",
    "        std = df.drop(columns='cover').std()\n",
    "        cover = df['cover']\n",
    "        df = (df - mea) / std\n",
    "        df['cover'] = cover\n",
    "    else:\n",
    "        df = (df - mea) / std\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# train = pd.read_csv('./raws/train_data.csv')\n",
    "# test = pd.read_csv('./raws/test_data.csv')\n",
    "train = pickle.load(open('./processed/shrinked_train.pkl', 'rb'))\n",
    "test = pickle.load(open('./processed/shrinked_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth_original feature estimating...\n",
      "===========================================================\n",
      "\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttrain's rmse: 0.844813\tval's rmse: 1.00773\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttrain's rmse: 0.783659\tval's rmse: 1.34252\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttrain's rmse: 0.813404\tval's rmse: 0.988994\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttrain's rmse: 0.803479\tval's rmse: 1.28713\n",
      "\n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ = featurecreation(train, 1)\n",
    "test_ = featurecreation(test, 0)\n",
    "\n",
    "pickle.dump(train_, open('./processed/lgb_train.pkl', 'wb'))\n",
    "pickle.dump(test_, open('./processed/lgb_test.pkl', 'wb'))\n",
    "\n",
    "train_ = make_nn_data(train_, 1)\n",
    "test_ = make_nn_data(test_, 0)\n",
    "\n",
    "pickle.dump(train_, open('./processed/nn_train.pkl', 'wb'))\n",
    "pickle.dump(test_, open('./processed/nn_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_.clip(0, 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth_original</th>\n",
       "      <th>aicial_length</th>\n",
       "      <th>beach_length</th>\n",
       "      <th>coast_length</th>\n",
       "      <th>coastal_dist</th>\n",
       "      <th>cold_sst</th>\n",
       "      <th>depth</th>\n",
       "      <th>fetch</th>\n",
       "      <th>hist_cold_sst</th>\n",
       "      <th>hist_warm_sst</th>\n",
       "      <th>river_dist</th>\n",
       "      <th>warm_sst</th>\n",
       "      <th>sst_annual</th>\n",
       "      <th>sst_ymd</th>\n",
       "      <th>Chla_est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.526583</td>\n",
       "      <td>2.308732</td>\n",
       "      <td>-0.472764</td>\n",
       "      <td>0.767202</td>\n",
       "      <td>-0.447847</td>\n",
       "      <td>0.977763</td>\n",
       "      <td>-0.924419</td>\n",
       "      <td>-0.817028</td>\n",
       "      <td>0.936851</td>\n",
       "      <td>1.011987</td>\n",
       "      <td>-0.798753</td>\n",
       "      <td>0.624851</td>\n",
       "      <td>0.966570</td>\n",
       "      <td>-0.636261</td>\n",
       "      <td>-0.095732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.428186</td>\n",
       "      <td>-0.382668</td>\n",
       "      <td>2.094515</td>\n",
       "      <td>1.508481</td>\n",
       "      <td>-0.486178</td>\n",
       "      <td>0.984934</td>\n",
       "      <td>1.090731</td>\n",
       "      <td>-1.774321</td>\n",
       "      <td>0.935334</td>\n",
       "      <td>0.406273</td>\n",
       "      <td>-0.649615</td>\n",
       "      <td>1.223371</td>\n",
       "      <td>0.965129</td>\n",
       "      <td>1.230732</td>\n",
       "      <td>-0.095732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058741</td>\n",
       "      <td>-0.083733</td>\n",
       "      <td>1.088644</td>\n",
       "      <td>0.969124</td>\n",
       "      <td>-0.573294</td>\n",
       "      <td>-1.104054</td>\n",
       "      <td>-0.377011</td>\n",
       "      <td>-0.452031</td>\n",
       "      <td>-0.665990</td>\n",
       "      <td>0.272542</td>\n",
       "      <td>-0.646942</td>\n",
       "      <td>-0.386732</td>\n",
       "      <td>-1.054618</td>\n",
       "      <td>-2.191642</td>\n",
       "      <td>-0.095732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.493328</td>\n",
       "      <td>-0.382668</td>\n",
       "      <td>-1.111069</td>\n",
       "      <td>-1.145003</td>\n",
       "      <td>-0.601171</td>\n",
       "      <td>-0.583171</td>\n",
       "      <td>0.101931</td>\n",
       "      <td>-0.821432</td>\n",
       "      <td>0.134596</td>\n",
       "      <td>-0.297053</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>-1.621510</td>\n",
       "      <td>-0.621779</td>\n",
       "      <td>0.985235</td>\n",
       "      <td>2.215099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.645780</td>\n",
       "      <td>-0.253607</td>\n",
       "      <td>-0.320310</td>\n",
       "      <td>-0.424078</td>\n",
       "      <td>-0.137714</td>\n",
       "      <td>0.531860</td>\n",
       "      <td>-0.924419</td>\n",
       "      <td>-1.970255</td>\n",
       "      <td>0.731376</td>\n",
       "      <td>-0.791884</td>\n",
       "      <td>1.930360</td>\n",
       "      <td>0.163593</td>\n",
       "      <td>0.563853</td>\n",
       "      <td>0.095865</td>\n",
       "      <td>-1.320249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>-1.538503</td>\n",
       "      <td>-0.306280</td>\n",
       "      <td>0.159317</td>\n",
       "      <td>-0.054140</td>\n",
       "      <td>-0.378154</td>\n",
       "      <td>-1.160246</td>\n",
       "      <td>0.541098</td>\n",
       "      <td>-0.313202</td>\n",
       "      <td>-0.996104</td>\n",
       "      <td>-0.315032</td>\n",
       "      <td>-0.679310</td>\n",
       "      <td>-1.303190</td>\n",
       "      <td>-1.211069</td>\n",
       "      <td>0.573896</td>\n",
       "      <td>-0.275556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>-0.603355</td>\n",
       "      <td>-0.382668</td>\n",
       "      <td>-1.030628</td>\n",
       "      <td>-1.078417</td>\n",
       "      <td>-0.043628</td>\n",
       "      <td>0.997756</td>\n",
       "      <td>0.686703</td>\n",
       "      <td>0.779535</td>\n",
       "      <td>0.946537</td>\n",
       "      <td>1.120150</td>\n",
       "      <td>-0.739830</td>\n",
       "      <td>0.540590</td>\n",
       "      <td>0.989261</td>\n",
       "      <td>-0.478101</td>\n",
       "      <td>0.550241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>-1.574262</td>\n",
       "      <td>0.111113</td>\n",
       "      <td>2.054972</td>\n",
       "      <td>1.875415</td>\n",
       "      <td>-0.594202</td>\n",
       "      <td>-1.109379</td>\n",
       "      <td>-0.924419</td>\n",
       "      <td>-0.889888</td>\n",
       "      <td>-0.688279</td>\n",
       "      <td>0.261927</td>\n",
       "      <td>-0.645451</td>\n",
       "      <td>-0.360262</td>\n",
       "      <td>-1.062047</td>\n",
       "      <td>-2.195682</td>\n",
       "      <td>-0.095732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>-0.467375</td>\n",
       "      <td>-0.382668</td>\n",
       "      <td>0.399136</td>\n",
       "      <td>0.245577</td>\n",
       "      <td>-0.566324</td>\n",
       "      <td>1.381217</td>\n",
       "      <td>-0.021358</td>\n",
       "      <td>0.039867</td>\n",
       "      <td>0.969969</td>\n",
       "      <td>1.652443</td>\n",
       "      <td>-0.236762</td>\n",
       "      <td>0.972528</td>\n",
       "      <td>1.411566</td>\n",
       "      <td>-1.291243</td>\n",
       "      <td>-1.639349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>-1.562342</td>\n",
       "      <td>-0.210343</td>\n",
       "      <td>0.124162</td>\n",
       "      <td>-0.033913</td>\n",
       "      <td>-0.238768</td>\n",
       "      <td>0.493430</td>\n",
       "      <td>-0.924419</td>\n",
       "      <td>-0.537782</td>\n",
       "      <td>0.520185</td>\n",
       "      <td>-0.493517</td>\n",
       "      <td>1.922197</td>\n",
       "      <td>0.604305</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>-0.095732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4039 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      depth_original  aicial_length  beach_length  coast_length  coastal_dist  \\\n",
       "0          -1.526583       2.308732     -0.472764      0.767202     -0.447847   \n",
       "1          -0.428186      -0.382668      2.094515      1.508481     -0.486178   \n",
       "2           0.058741      -0.083733      1.088644      0.969124     -0.573294   \n",
       "3          -0.493328      -0.382668     -1.111069     -1.145003     -0.601171   \n",
       "4          -1.645780      -0.253607     -0.320310     -0.424078     -0.137714   \n",
       "...              ...            ...           ...           ...           ...   \n",
       "4034       -1.538503      -0.306280      0.159317     -0.054140     -0.378154   \n",
       "4035       -0.603355      -0.382668     -1.030628     -1.078417     -0.043628   \n",
       "4036       -1.574262       0.111113      2.054972      1.875415     -0.594202   \n",
       "4037       -0.467375      -0.382668      0.399136      0.245577     -0.566324   \n",
       "4038       -1.562342      -0.210343      0.124162     -0.033913     -0.238768   \n",
       "\n",
       "      cold_sst     depth     fetch  hist_cold_sst  hist_warm_sst  river_dist  \\\n",
       "0     0.977763 -0.924419 -0.817028       0.936851       1.011987   -0.798753   \n",
       "1     0.984934  1.090731 -1.774321       0.935334       0.406273   -0.649615   \n",
       "2    -1.104054 -0.377011 -0.452031      -0.665990       0.272542   -0.646942   \n",
       "3    -0.583171  0.101931 -0.821432       0.134596      -0.297053    0.006226   \n",
       "4     0.531860 -0.924419 -1.970255       0.731376      -0.791884    1.930360   \n",
       "...        ...       ...       ...            ...            ...         ...   \n",
       "4034 -1.160246  0.541098 -0.313202      -0.996104      -0.315032   -0.679310   \n",
       "4035  0.997756  0.686703  0.779535       0.946537       1.120150   -0.739830   \n",
       "4036 -1.109379 -0.924419 -0.889888      -0.688279       0.261927   -0.645451   \n",
       "4037  1.381217 -0.021358  0.039867       0.969969       1.652443   -0.236762   \n",
       "4038  0.493430 -0.924419 -0.537782       0.520185      -0.493517    1.922197   \n",
       "\n",
       "      warm_sst  sst_annual   sst_ymd  Chla_est  \n",
       "0     0.624851    0.966570 -0.636261 -0.095732  \n",
       "1     1.223371    0.965129  1.230732 -0.095732  \n",
       "2    -0.386732   -1.054618 -2.191642 -0.095732  \n",
       "3    -1.621510   -0.621779  0.985235  2.215099  \n",
       "4     0.163593    0.563853  0.095865 -1.320249  \n",
       "...        ...         ...       ...       ...  \n",
       "4034 -1.303190   -1.211069  0.573896 -0.275556  \n",
       "4035  0.540590    0.989261 -0.478101  0.550241  \n",
       "4036 -0.360262   -1.062047 -2.195682 -0.095732  \n",
       "4037  0.972528    1.411566 -1.291243 -1.639349  \n",
       "4038  0.604305    0.541176  0.071449 -0.095732  \n",
       "\n",
       "[4039 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "08-bluecarbon-CvTXT7p5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "276441da38dc6a3e251be116a0d14b55ec747c854d559d41bae05c76a1593c62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
